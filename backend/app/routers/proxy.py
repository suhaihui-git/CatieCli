from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import StreamingResponse, JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from datetime import date, datetime, timedelta
from typing import Optional
import json
import time

from app.database import get_db
from app.models.user import User, UsageLog
from app.services.auth import get_user_by_api_key
from app.services.credential_pool import CredentialPool
from app.services.gemini_client import GeminiClient
from app.services.websocket import notify_log_update, notify_stats_update
from app.config import settings

router = APIRouter(tags=["APIä»£ç†"])


async def get_user_from_api_key(request: Request, db: AsyncSession = Depends(get_db)) -> User:
    """ä»è¯·æ±‚ä¸­æå–API Keyå¹¶éªŒè¯ç”¨æˆ·"""
    api_key = None
    
    # 1. ä»Authorization headerè·å–
    auth_header = request.headers.get("Authorization", "")
    if auth_header.startswith("Bearer "):
        api_key = auth_header[7:]
    
    # 2. ä»x-api-key headerè·å–
    if not api_key:
        api_key = request.headers.get("x-api-key")
    
    # 3. ä»æŸ¥è¯¢å‚æ•°è·å–
    if not api_key:
        api_key = request.query_params.get("key")
    
    if not api_key:
        raise HTTPException(status_code=401, detail="æœªæä¾›API Key")
    
    user = await get_user_by_api_key(db, api_key)
    if not user:
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„API Key")
    
    if not user.is_active:
        raise HTTPException(status_code=403, detail="è´¦æˆ·å·²è¢«ç¦ç”¨")
    
    # æ£€æŸ¥é…é¢
    today = date.today()
    result = await db.execute(
        select(func.count(UsageLog.id))
        .where(UsageLog.user_id == user.id)
        .where(func.date(UsageLog.created_at) == today)
    )
    today_usage = result.scalar() or 0
    
    if today_usage >= user.daily_quota:
        raise HTTPException(status_code=429, detail="å·²è¾¾åˆ°ä»Šæ—¥é…é¢é™åˆ¶")
    
    return user


@router.options("/v1/chat/completions")
@router.options("/chat/completions")
@router.options("/v1/models")
@router.options("/models")
async def options_handler():
    """å¤„ç† CORS é¢„æ£€è¯·æ±‚"""
    return JSONResponse(content={}, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
    })


@router.get("/v1/models")
@router.get("/models")
async def list_models(user: User = Depends(get_user_from_api_key)):
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹ (OpenAIå…¼å®¹)"""
    # åŸºç¡€æ¨¡å‹ (Gemini 2.5+)
    base_models = [
        "gemini-2.5-pro",
        "gemini-2.5-flash", 
        "gemini-3-pro-preview",
    ]
    
    # Thinking åç¼€
    thinking_suffixes = ["-maxthinking", "-nothinking"]
    # Search åç¼€
    search_suffix = "-search"
    
    models = []
    for base in base_models:
        # åŸºç¡€æ¨¡å‹
        models.append({"id": base, "object": "model", "owned_by": "google"})
        
        # å‡æµå¼æ¨¡å‹
        models.append({"id": f"å‡æµå¼/{base}", "object": "model", "owned_by": "google"})
        # æµå¼æŠ—æˆªæ–­æ¨¡å‹
        models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}", "object": "model", "owned_by": "google"})
        
        # thinking å˜ä½“
        for suffix in thinking_suffixes:
            models.append({"id": f"{base}{suffix}", "object": "model", "owned_by": "google"})
            models.append({"id": f"å‡æµå¼/{base}{suffix}", "object": "model", "owned_by": "google"})
            models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{suffix}", "object": "model", "owned_by": "google"})
        
        # search å˜ä½“
        models.append({"id": f"{base}{search_suffix}", "object": "model", "owned_by": "google"})
        models.append({"id": f"å‡æµå¼/{base}{search_suffix}", "object": "model", "owned_by": "google"})
        models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{search_suffix}", "object": "model", "owned_by": "google"})
        
        # thinking + search ç»„åˆ
        for suffix in thinking_suffixes:
            combined = f"{suffix}{search_suffix}"
            models.append({"id": f"{base}{combined}", "object": "model", "owned_by": "google"})
            models.append({"id": f"å‡æµå¼/{base}{combined}", "object": "model", "owned_by": "google"})
            models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{combined}", "object": "model", "owned_by": "google"})
    
    # Image æ¨¡å‹
    models.append({"id": "gemini-2.5-flash-image", "object": "model", "owned_by": "google"})
    
    
    return {"object": "list", "data": models}


@router.post("/v1/chat/completions")
@router.post("/chat/completions")
async def chat_completions(
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Chat Completions (OpenAIå…¼å®¹)"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    model = body.get("model", "gemini-2.5-flash")
    messages = body.get("messages", [])
    stream = body.get("stream", False)
    
    if not messages:
        raise HTTPException(status_code=400, detail="messagesä¸èƒ½ä¸ºç©º")
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶æ£€æŸ¥ (RPM)
    one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
    rpm_result = await db.execute(
        select(func.count(UsageLog.id))
        .where(UsageLog.user_id == user.id)
        .where(UsageLog.created_at >= one_minute_ago)
    )
    current_rpm = rpm_result.scalar() or 0
    max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
    
    if current_rpm >= max_rpm:
        raise HTTPException(
            status_code=429, 
            detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿã€‚{'ä¸Šä¼ å‡­è¯å¯æå‡è‡³ ' + str(settings.contributor_rpm) + ' æ¬¡/åˆ†é’Ÿ' if not user_has_public else ''}"
        )
    
    # é‡è¯•é€»è¾‘ï¼šæŠ¥é”™æ—¶åˆ‡æ¢å‡­è¯é‡è¯•
    max_retries = settings.error_retry_count
    last_error = None
    tried_credential_ids = set()
    
    for retry_attempt in range(max_retries + 1):
        # è·å–å‡­è¯ï¼ˆå¤§é”…é¥­è§„åˆ™ + æ¨¡å‹ç­‰çº§åŒ¹é…ï¼‰
        credential = await CredentialPool.get_available_credential(
            db, 
            user_id=user.id,
            user_has_public_creds=user_has_public,
            model=model,
            exclude_ids=tried_credential_ids  # æ’é™¤å·²å°è¯•è¿‡çš„å‡­è¯
        )
        if not credential:
            if retry_attempt > 0:
                # å·²ç»é‡è¯•è¿‡ï¼Œæ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†
                raise HTTPException(status_code=503, detail=f"æ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†ï¼ˆå·²é‡è¯• {retry_attempt} æ¬¡ï¼‰: {last_error}")
            required_tier = CredentialPool.get_required_tier(model)
            if required_tier == "3":
                raise HTTPException(
                    status_code=503, 
                    detail="æ²¡æœ‰å¯ç”¨çš„ Gemini 3 ç­‰çº§å‡­è¯ã€‚è¯¥æ¨¡å‹éœ€è¦æœ‰ Gemini 3 èµ„æ ¼çš„å‡­è¯ã€‚"
                )
            if not user_has_public:
                raise HTTPException(
                    status_code=503, 
                    detail="æ‚¨æ²¡æœ‰å¯ç”¨å‡­è¯ã€‚è¯·åœ¨å‡­è¯ç®¡ç†é¡µé¢ä¸Šä¼ å‡­è¯ï¼Œæˆ–æèµ å‡­è¯ä»¥ä½¿ç”¨å…¬å…±æ± ã€‚"
                )
            raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯ï¼Œè¯·ç¨åé‡è¯•")
        
        tried_credential_ids.add(credential.id)
        
        # è·å– access_tokenï¼ˆè‡ªåŠ¨åˆ·æ–°ï¼‰
        access_token = await CredentialPool.get_access_token(credential, db)
        if not access_token:
            await CredentialPool.mark_credential_error(db, credential.id, "Token åˆ·æ–°å¤±è´¥")
            last_error = "Token åˆ·æ–°å¤±è´¥"
            print(f"[Proxy] âš ï¸ å‡­è¯ {credential.email} Token åˆ·æ–°å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå‡­è¯ ({retry_attempt + 1}/{max_retries + 1})", flush=True)
            continue
        
        # è·å– project_id
        project_id = credential.project_id or ""
        print(f"[Proxy] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model} (å°è¯• {retry_attempt + 1}/{max_retries + 1})", flush=True)
        
        if not project_id:
            print(f"[Proxy] âš ï¸ å‡­è¯ {credential.email} æ²¡æœ‰ project_id!", flush=True)
        
        client = GeminiClient(access_token, project_id)
        
        # è®°å½•ä½¿ç”¨æ—¥å¿—
        async def log_usage(status_code: int = 200, cred=credential):
            latency = (time.time() - start_time) * 1000
            log = UsageLog(
                user_id=user.id,
                credential_id=cred.id,
                model=model,
                endpoint="/v1/chat/completions",
                status_code=status_code,
                latency_ms=latency
            )
            db.add(log)
            await db.commit()
            
            # æ›´æ–°å‡­è¯ä½¿ç”¨æ¬¡æ•°
            cred.total_requests = (cred.total_requests or 0) + 1
            cred.last_used_at = datetime.utcnow()
            await db.commit()
            
            # WebSocket å®æ—¶é€šçŸ¥
            await notify_log_update({
                "username": user.username,
                "model": model,
                "status_code": status_code,
                "latency_ms": round(latency, 0),
                "created_at": datetime.utcnow().isoformat()
            })
            await notify_stats_update()
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å‡æµå¼
        use_fake_streaming = client.is_fake_streaming(model)
        
        try:
            if stream:
                # æµå¼æ¨¡å¼ï¼šä½¿ç”¨å¸¦é‡è¯•çš„æµç”Ÿæˆå™¨
                async def stream_generator_with_retry():
                    nonlocal credential, access_token, project_id, client, tried_credential_ids, last_error
                    
                    for stream_retry in range(max_retries + 1):
                        try:
                            if use_fake_streaming:
                                async for chunk in client.chat_completions_fake_stream(
                                    model=model,
                                    messages=messages,
                                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                                ):
                                    yield chunk
                            else:
                                async for chunk in client.chat_completions_stream(
                                    model=model,
                                    messages=messages,
                                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                                ):
                                    yield chunk
                                yield "data: [DONE]\n\n"
                            await log_usage(cred=credential)
                            return  # æˆåŠŸï¼Œé€€å‡º
                        except Exception as e:
                            error_str = str(e)
                            await CredentialPool.handle_credential_failure(db, credential.id, error_str)
                            last_error = error_str
                            
                            # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•ï¼ˆ404ã€500ã€503 ç­‰é”™è¯¯ï¼‰
                            should_retry = any(code in error_str for code in ["404", "500", "503", "429", "RESOURCE_EXHAUSTED", "NOT_FOUND"])
                            
                            if should_retry and stream_retry < max_retries:
                                print(f"[Proxy] âš ï¸ æµå¼è¯·æ±‚å¤±è´¥: {error_str}ï¼Œåˆ‡æ¢å‡­è¯é‡è¯• ({stream_retry + 2}/{max_retries + 1})", flush=True)
                                
                                # è·å–æ–°å‡­è¯
                                new_credential = await CredentialPool.get_available_credential(
                                    db, user_id=user.id, user_has_public_creds=user_has_public,
                                    model=model, exclude_ids=tried_credential_ids
                                )
                                if new_credential:
                                    tried_credential_ids.add(new_credential.id)
                                    new_token = await CredentialPool.get_access_token(new_credential, db)
                                    if new_token:
                                        credential = new_credential
                                        access_token = new_token
                                        project_id = new_credential.project_id or ""
                                        client = GeminiClient(access_token, project_id)
                                        print(f"[Proxy] ğŸ”„ åˆ‡æ¢åˆ°å‡­è¯: {credential.email}", flush=True)
                                        continue
                            
                            # æ— æ³•é‡è¯•ï¼Œè¾“å‡ºé”™è¯¯
                            await log_usage(500, cred=credential)
                            yield f"data: {json.dumps({'error': f'API Error (å·²é‡è¯• {stream_retry + 1} æ¬¡): {error_str}'})}\n\n"
                            return
                
                return StreamingResponse(
                    stream_generator_with_retry(),
                    media_type="text/event-stream",
                    headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
                )
            else:
                # éæµå¼æ¨¡å¼
                result = await client.chat_completions(
                    model=model,
                    messages=messages,
                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                )
                await log_usage()
                return JSONResponse(content=result)
        
        except Exception as e:
            error_str = str(e)
            await CredentialPool.handle_credential_failure(db, credential.id, error_str)
            last_error = error_str
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
            should_retry = any(code in error_str for code in ["404", "500", "503", "429", "RESOURCE_EXHAUSTED", "NOT_FOUND"])
            
            if should_retry and retry_attempt < max_retries:
                print(f"[Proxy] âš ï¸ è¯·æ±‚å¤±è´¥: {error_str}ï¼Œåˆ‡æ¢å‡­è¯é‡è¯• ({retry_attempt + 2}/{max_retries + 1})", flush=True)
                continue
            
            await log_usage(500)
            raise HTTPException(status_code=500, detail=f"APIè°ƒç”¨å¤±è´¥ (å·²é‡è¯• {retry_attempt + 1} æ¬¡): {error_str}")
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise HTTPException(status_code=503, detail=f"æ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†: {last_error}")


# ===== Gemini åŸç”Ÿæ¥å£æ”¯æŒ =====

@router.options("/v1beta/models/{model:path}:generateContent")
@router.options("/v1/models/{model:path}:generateContent")
@router.options("/v1beta/models/{model:path}:streamGenerateContent")
@router.options("/v1/models/{model:path}:streamGenerateContent")
async def gemini_options_handler(model: str):
    """Gemini æ¥å£ CORS é¢„æ£€"""
    return JSONResponse(content={}, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
    })


@router.get("/v1beta/models")
@router.get("/v1/v1beta/models")
async def list_gemini_models(user: User = Depends(get_user_from_api_key)):
    """Gemini æ ¼å¼æ¨¡å‹åˆ—è¡¨"""
    base_models = [
        "gemini-2.5-pro", "gemini-2.5-flash", 
        "gemini-3-pro-preview",
    ]
    
    models = []
    for base in base_models:
        models.append({
            "name": f"models/{base}",
            "version": "001",
            "displayName": base,
            "description": f"Gemini {base} model",
            "inputTokenLimit": 1000000,
            "outputTokenLimit": 65536,
            "supportedGenerationMethods": ["generateContent", "streamGenerateContent"],
        })
    
    return {"models": models}


@router.post("/v1beta/models/{model:path}:generateContent")
@router.post("/v1/models/{model:path}:generateContent")
@router.post("/v1/v1beta/models/{model:path}:generateContent")
async def gemini_generate_content(
    model: str,
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Gemini åŸç”Ÿ generateContent æ¥å£"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    contents = body.get("contents", [])
    if not contents:
        raise HTTPException(status_code=400, detail="contentsä¸èƒ½ä¸ºç©º")
    
    # æ¸…ç†æ¨¡å‹åï¼ˆç§»é™¤ models/ å‰ç¼€ï¼‰
    if model.startswith("models/"):
        model = model[7:]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶
    one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
    rpm_result = await db.execute(
        select(func.count(UsageLog.id))
        .where(UsageLog.user_id == user.id)
        .where(UsageLog.created_at >= one_minute_ago)
    )
    current_rpm = rpm_result.scalar() or 0
    max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
    
    if current_rpm >= max_rpm:
        raise HTTPException(status_code=429, detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿ")
    
    # è·å–å‡­è¯
    credential = await CredentialPool.get_available_credential(
        db, user_id=user.id, user_has_public_creds=user_has_public, model=model
    )
    if not credential:
        raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯")
    
    access_token = await CredentialPool.get_access_token(credential, db)
    if not access_token:
        raise HTTPException(status_code=503, detail="å‡­è¯å·²å¤±æ•ˆ")
    
    project_id = credential.project_id or ""
    print(f"[Gemini API] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model}", flush=True)
    
    # è®°å½•æ—¥å¿—
    async def log_usage(status_code: int = 200):
        latency = (time.time() - start_time) * 1000
        log = UsageLog(user_id=user.id, credential_id=credential.id, model=model, endpoint="/v1beta/generateContent", status_code=status_code, latency_ms=latency)
        db.add(log)
        credential.total_requests = (credential.total_requests or 0) + 1
        credential.last_used_at = datetime.utcnow()
        await db.commit()
    
    # ç›´æ¥è½¬å‘åˆ° Google API
    try:
        import httpx
        url = "https://cloudcode-pa.googleapis.com/v1internal:generateContent"
        
        # æ„å»º payload
        request_body = {"contents": contents}
        if "generationConfig" in body:
            request_body["generationConfig"] = body["generationConfig"]
        if "systemInstruction" in body:
            request_body["systemInstruction"] = body["systemInstruction"]
        if "safetySettings" in body:
            request_body["safetySettings"] = body["safetySettings"]
        if "tools" in body:
            request_body["tools"] = body["tools"]
        
        payload = {"model": model, "project": project_id, "request": request_body}
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                url,
                headers={"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"},
                json=payload
            )
            
            if response.status_code != 200:
                error_text = response.text[:500]
                print(f"[Gemini API] âŒ é”™è¯¯ {response.status_code}: {error_text}", flush=True)
                # 401/403 é”™è¯¯è‡ªåŠ¨ç¦ç”¨å‡­è¯
                if response.status_code in [401, 403]:
                    await CredentialPool.handle_credential_failure(db, credential.id, f"API Error {response.status_code}: {error_text}")
                await log_usage(response.status_code)
                raise HTTPException(status_code=response.status_code, detail=response.text)
            
            await log_usage()
            return JSONResponse(content=response.json())
    
    except HTTPException:
        raise
    except Exception as e:
        await CredentialPool.handle_credential_failure(db, credential.id, str(e))
        await log_usage(500)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/v1beta/models/{model:path}:streamGenerateContent")
@router.post("/v1/models/{model:path}:streamGenerateContent")
@router.post("/v1/v1beta/models/{model:path}:streamGenerateContent")
async def gemini_stream_generate_content(
    model: str,
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Gemini åŸç”Ÿ streamGenerateContent æ¥å£"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    contents = body.get("contents", [])
    if not contents:
        raise HTTPException(status_code=400, detail="contentsä¸èƒ½ä¸ºç©º")
    
    # æ¸…ç†æ¨¡å‹å
    if model.startswith("models/"):
        model = model[7:]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶
    one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
    rpm_result = await db.execute(
        select(func.count(UsageLog.id))
        .where(UsageLog.user_id == user.id)
        .where(UsageLog.created_at >= one_minute_ago)
    )
    current_rpm = rpm_result.scalar() or 0
    max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
    
    if current_rpm >= max_rpm:
        raise HTTPException(status_code=429, detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿ")
    
    # è·å–å‡­è¯
    credential = await CredentialPool.get_available_credential(
        db, user_id=user.id, user_has_public_creds=user_has_public, model=model
    )
    if not credential:
        raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯")
    
    access_token = await CredentialPool.get_access_token(credential, db)
    if not access_token:
        raise HTTPException(status_code=503, detail="å‡­è¯å·²å¤±æ•ˆ")
    
    project_id = credential.project_id or ""
    print(f"[Gemini Stream] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model}", flush=True)
    
    # è®°å½•æ—¥å¿—
    async def log_usage(status_code: int = 200):
        latency = (time.time() - start_time) * 1000
        log = UsageLog(user_id=user.id, credential_id=credential.id, model=model, endpoint="/v1beta/streamGenerateContent", status_code=status_code, latency_ms=latency)
        db.add(log)
        credential.total_requests = (credential.total_requests or 0) + 1
        credential.last_used_at = datetime.utcnow()
        await db.commit()
    
    # æµå¼è½¬å‘
    import httpx
    url = "https://cloudcode-pa.googleapis.com/v1internal:streamGenerateContent?alt=sse"
    
    request_body = {"contents": contents}
    if "generationConfig" in body:
        request_body["generationConfig"] = body["generationConfig"]
    if "systemInstruction" in body:
        request_body["systemInstruction"] = body["systemInstruction"]
    if "safetySettings" in body:
        request_body["safetySettings"] = body["safetySettings"]
    if "tools" in body:
        request_body["tools"] = body["tools"]
    
    payload = {"model": model, "project": project_id, "request": request_body}
    
    async def stream_generator():
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                async with client.stream(
                    "POST", url,
                    headers={"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"},
                    json=payload
                ) as response:
                    if response.status_code != 200:
                        error = await response.aread()
                        error_text = error.decode()[:500]
                        print(f"[Gemini Stream] âŒ é”™è¯¯ {response.status_code}: {error_text}", flush=True)
                        # 401/403 é”™è¯¯è‡ªåŠ¨ç¦ç”¨å‡­è¯
                        if response.status_code in [401, 403]:
                            await CredentialPool.handle_credential_failure(db, credential.id, f"API Error {response.status_code}: {error_text}")
                        yield f"data: {json.dumps({'error': error.decode()})}\n\n"
                        return
                    
                    async for line in response.aiter_lines():
                        if line:
                            yield f"{line}\n"
            
            await log_usage()
        except Exception as e:
            await CredentialPool.handle_credential_failure(db, credential.id, str(e))
            await log_usage(500)
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return StreamingResponse(
        stream_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )
