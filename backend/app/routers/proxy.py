from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import StreamingResponse, JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from datetime import date, datetime, timedelta
from typing import Optional
import json
import time

from app.database import get_db
from app.models.user import User, UsageLog
from app.services.auth import get_user_by_api_key
from app.services.credential_pool import CredentialPool
from app.services.gemini_client import GeminiClient
from app.services.websocket import notify_log_update, notify_stats_update
from app.config import settings

router = APIRouter(tags=["APIä»£ç†"])


async def get_user_from_api_key(request: Request, db: AsyncSession = Depends(get_db)) -> User:
    """ä»è¯·æ±‚ä¸­æå–API Keyå¹¶éªŒè¯ç”¨æˆ·"""
    api_key = None
    
    # 1. ä»Authorization headerè·å–
    auth_header = request.headers.get("Authorization", "")
    if auth_header.startswith("Bearer "):
        api_key = auth_header[7:]
    
    # 2. ä»x-api-key headerè·å–
    if not api_key:
        api_key = request.headers.get("x-api-key")
    
    # 3. ä»æŸ¥è¯¢å‚æ•°è·å–
    if not api_key:
        api_key = request.query_params.get("key")
    
    if not api_key:
        raise HTTPException(status_code=401, detail="æœªæä¾›API Key")
    
    user = await get_user_by_api_key(db, api_key)
    if not user:
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„API Key")
    
    if not user.is_active:
        raise HTTPException(status_code=403, detail="è´¦æˆ·å·²è¢«ç¦ç”¨")
    
    # æ£€æŸ¥é…é¢
    # é…é¢åœ¨åŒ—äº¬æ—¶é—´ 15:00 (UTC 07:00) é‡ç½®
    now = datetime.utcnow()
    reset_time_utc = now.replace(hour=7, minute=0, second=0, microsecond=0)
    if now < reset_time_utc:
        start_of_day = reset_time_utc - timedelta(days=1)
    else:
        start_of_day = reset_time_utc

    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœ‰æ•ˆå‡­è¯
    from app.models.user import Credential
    cred_result = await db.execute(
        select(func.count(Credential.id))
        .where(Credential.user_id == user.id)
        .where(Credential.is_active == True)
    )
    has_credential = (cred_result.scalar() or 0) > 0

    # æ ¹æ®æ˜¯å¦æœ‰å‡­è¯ï¼Œåº”ç”¨ä¸åŒçš„é…é¢é€»è¾‘
    if has_credential:
        # æœ‰å‡­è¯ç”¨æˆ·ï¼šæ£€æŸ¥æ€»é…é¢
        total_usage_result = await db.execute(
            select(func.count(UsageLog.id))
            .where(UsageLog.user_id == user.id)
            .where(UsageLog.created_at >= start_of_day)
        )
        if (total_usage_result.scalar() or 0) >= user.daily_quota:
            raise HTTPException(status_code=429, detail="å·²è¾¾åˆ°ä»Šæ—¥æ€»é…é¢é™åˆ¶")
    else:
        # æ— å‡­è¯ç”¨æˆ·ï¼šæŒ‰æ¨¡å‹æ£€æŸ¥é…é¢
        body = await request.json()
        model = body.get("model", "gemini-2.5-flash")
        
        # ç¡®å®šæ¨¡å‹ç±»å‹å’Œå¯¹åº”é…é¢
        required_tier = CredentialPool.get_required_tier(model)
        quota_limit = 0
        if required_tier == "3":
            quota_limit = settings.no_cred_quota_30pro
        elif "pro" in model:
            quota_limit = settings.no_cred_quota_25pro
        else: # é»˜è®¤ flash
            quota_limit = settings.no_cred_quota_flash

        if quota_limit > 0:
            # æŸ¥è¯¢è¯¥ç”¨æˆ·ä»Šå¤©å¯¹è¯¥ç­‰çº§æ¨¡å‹çš„ä½¿ç”¨é‡
            model_usage_query = select(func.count(UsageLog.id)).where(
                UsageLog.user_id == user.id,
                UsageLog.created_at >= start_of_day
            )
            if required_tier == "3":
                model_usage_query = model_usage_query.where(UsageLog.model.like('%3%'))
            elif "pro" in model:
                model_usage_query = model_usage_query.where(UsageLog.model.like('%pro%'))
            else: # flash
                model_usage_query = model_usage_query.where(UsageLog.model.notlike('%pro%'))

            model_usage_result = await db.execute(model_usage_query)
            if (model_usage_result.scalar() or 0) >= quota_limit:
                raise HTTPException(status_code=429, detail=f"å·²è¾¾åˆ°è¯¥æ¨¡å‹ç­‰çº§çš„æ¯æ—¥é…é¢é™åˆ¶ ({quota_limit}æ¬¡)")
    
    return user


@router.options("/v1/chat/completions")
@router.options("/chat/completions")
@router.options("/v1/models")
@router.options("/models")
async def options_handler():
    """å¤„ç† CORS é¢„æ£€è¯·æ±‚"""
    return JSONResponse(content={}, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
    })


@router.get("/v1/models")
@router.get("/models")
async def list_models(request: Request, user: User = Depends(get_user_from_api_key), db: AsyncSession = Depends(get_db)):
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹ (OpenAIå…¼å®¹)"""
    from app.models.user import Credential
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ 3.0 å‡­è¯
    has_tier3_creds = await CredentialPool.has_tier3_credentials(user, db)
    
    has_tier3 = await CredentialPool.has_tier3_credentials(user, db)
    
    # åŸºç¡€æ¨¡å‹ (Gemini 2.5+)
    base_models = [
        "gemini-2.5-pro",
        "gemini-2.5-flash",
    ]
    
    # åªæœ‰æœ‰ 3.0 å‡­è¯æ—¶æ‰æ·»åŠ  3.0 æ¨¡å‹
    if has_tier3:
        base_models.append("gemini-3-pro-preview")
    
    # Thinking åç¼€
    thinking_suffixes = ["-maxthinking", "-nothinking"]
    # Search åç¼€
    search_suffix = "-search"
    
    models = []
    for base in base_models:
        # åŸºç¡€æ¨¡å‹
        models.append({"id": base, "object": "model", "owned_by": "google"})
        
        # å‡æµå¼æ¨¡å‹
        models.append({"id": f"å‡æµå¼/{base}", "object": "model", "owned_by": "google"})
        # æµå¼æŠ—æˆªæ–­æ¨¡å‹
        models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}", "object": "model", "owned_by": "google"})
        
        # thinking å˜ä½“
        for suffix in thinking_suffixes:
            models.append({"id": f"{base}{suffix}", "object": "model", "owned_by": "google"})
            models.append({"id": f"å‡æµå¼/{base}{suffix}", "object": "model", "owned_by": "google"})
            models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{suffix}", "object": "model", "owned_by": "google"})
        
        # search å˜ä½“
        models.append({"id": f"{base}{search_suffix}", "object": "model", "owned_by": "google"})
        models.append({"id": f"å‡æµå¼/{base}{search_suffix}", "object": "model", "owned_by": "google"})
        models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{search_suffix}", "object": "model", "owned_by": "google"})
        
        # thinking + search ç»„åˆ
        for suffix in thinking_suffixes:
            combined = f"{suffix}{search_suffix}"
            models.append({"id": f"{base}{combined}", "object": "model", "owned_by": "google"})
            models.append({"id": f"å‡æµå¼/{base}{combined}", "object": "model", "owned_by": "google"})
            models.append({"id": f"æµå¼æŠ—æˆªæ–­/{base}{combined}", "object": "model", "owned_by": "google"})
    
    # Image æ¨¡å‹
    models.append({"id": "gemini-2.5-flash-image", "object": "model", "owned_by": "google"})
    
    
    return {"object": "list", "data": models}


@router.post("/v1/chat/completions")
@router.post("/chat/completions")
async def chat_completions(
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Chat Completions (OpenAIå…¼å®¹)"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    model = body.get("model", "gemini-2.5-flash")
    messages = body.get("messages", [])
    stream = body.get("stream", False)
    
    if not messages:
        raise HTTPException(status_code=400, detail="messagesä¸èƒ½ä¸ºç©º")
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶æ£€æŸ¥ (RPM) - ç®¡ç†å‘˜è±å…
    if not user.is_admin:
        one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
        rpm_result = await db.execute(
            select(func.count(UsageLog.id))
            .where(UsageLog.user_id == user.id)
            .where(UsageLog.created_at >= one_minute_ago)
        )
        current_rpm = rpm_result.scalar() or 0
        max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
        
        if current_rpm >= max_rpm:
            raise HTTPException(
                status_code=429, 
                detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿã€‚{'ä¸Šä¼ å‡­è¯å¯æå‡è‡³ ' + str(settings.contributor_rpm) + ' æ¬¡/åˆ†é’Ÿ' if not user_has_public else ''}"
            )
    
    # é‡è¯•é€»è¾‘ï¼šæŠ¥é”™æ—¶åˆ‡æ¢å‡­è¯é‡è¯•
    max_retries = settings.error_retry_count
    last_error = None
    tried_credential_ids = set()
    
    for retry_attempt in range(max_retries + 1):
        # è·å–å‡­è¯ï¼ˆå¤§é”…é¥­è§„åˆ™ + æ¨¡å‹ç­‰çº§åŒ¹é…ï¼‰
        credential = await CredentialPool.get_available_credential(
            db, 
            user_id=user.id,
            user_has_public_creds=user_has_public,
            model=model,
            exclude_ids=tried_credential_ids  # æ’é™¤å·²å°è¯•è¿‡çš„å‡­è¯
        )
        if not credential:
            if retry_attempt > 0:
                # å·²ç»é‡è¯•è¿‡ï¼Œæ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†
                raise HTTPException(status_code=503, detail=f"æ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†ï¼ˆå·²é‡è¯• {retry_attempt} æ¬¡ï¼‰: {last_error}")
            required_tier = CredentialPool.get_required_tier(model)
            if required_tier == "3":
                raise HTTPException(
                    status_code=503, 
                    detail="æ²¡æœ‰å¯ç”¨çš„ Gemini 3 ç­‰çº§å‡­è¯ã€‚è¯¥æ¨¡å‹éœ€è¦æœ‰ Gemini 3 èµ„æ ¼çš„å‡­è¯ã€‚"
                )
            if not user_has_public:
                raise HTTPException(
                    status_code=503, 
                    detail="æ‚¨æ²¡æœ‰å¯ç”¨å‡­è¯ã€‚è¯·åœ¨å‡­è¯ç®¡ç†é¡µé¢ä¸Šä¼ å‡­è¯ï¼Œæˆ–æèµ å‡­è¯ä»¥ä½¿ç”¨å…¬å…±æ± ã€‚"
                )
            raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯ï¼Œè¯·ç¨åé‡è¯•")
        
        tried_credential_ids.add(credential.id)
        
        # è·å– access_tokenï¼ˆè‡ªåŠ¨åˆ·æ–°ï¼‰
        access_token = await CredentialPool.get_access_token(credential, db)
        if not access_token:
            await CredentialPool.mark_credential_error(db, credential.id, "Token åˆ·æ–°å¤±è´¥")
            last_error = "Token åˆ·æ–°å¤±è´¥"
            print(f"[Proxy] âš ï¸ å‡­è¯ {credential.email} Token åˆ·æ–°å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå‡­è¯ ({retry_attempt + 1}/{max_retries + 1})", flush=True)
            continue
        
        # è·å– project_id
        project_id = credential.project_id or ""
        print(f"[Proxy] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model} (å°è¯• {retry_attempt + 1}/{max_retries + 1})", flush=True)
        
        if not project_id:
            print(f"[Proxy] âš ï¸ å‡­è¯ {credential.email} æ²¡æœ‰ project_id!", flush=True)
        
        client = GeminiClient(access_token, project_id)
        
        # è®°å½•ä½¿ç”¨æ—¥å¿—
        async def log_usage(status_code: int = 200, cred=credential):
            latency = (time.time() - start_time) * 1000
            log = UsageLog(
                user_id=user.id,
                credential_id=cred.id,
                model=model,
                endpoint="/v1/chat/completions",
                status_code=status_code,
                latency_ms=latency
            )
            db.add(log)
            await db.commit()
            
            # æ›´æ–°å‡­è¯ä½¿ç”¨æ¬¡æ•°
            cred.total_requests = (cred.total_requests or 0) + 1
            cred.last_used_at = datetime.utcnow()
            await db.commit()
            
            # WebSocket å®æ—¶é€šçŸ¥
            await notify_log_update({
                "username": user.username,
                "model": model,
                "status_code": status_code,
                "latency_ms": round(latency, 0),
                "created_at": datetime.utcnow().isoformat()
            })
            await notify_stats_update()
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å‡æµå¼
        use_fake_streaming = client.is_fake_streaming(model)
        
        try:
            if stream:
                # æµå¼æ¨¡å¼ï¼šä½¿ç”¨å¸¦é‡è¯•çš„æµç”Ÿæˆå™¨
                async def stream_generator_with_retry():
                    nonlocal credential, access_token, project_id, client, tried_credential_ids, last_error
                    
                    for stream_retry in range(max_retries + 1):
                        try:
                            if use_fake_streaming:
                                async for chunk in client.chat_completions_fake_stream(
                                    model=model,
                                    messages=messages,
                                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                                ):
                                    yield chunk
                            else:
                                async for chunk in client.chat_completions_stream(
                                    model=model,
                                    messages=messages,
                                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                                ):
                                    yield chunk
                                yield "data: [DONE]\n\n"
                            await log_usage(cred=credential)
                            return  # æˆåŠŸï¼Œé€€å‡º
                        except Exception as e:
                            error_str = str(e)
                            await CredentialPool.handle_credential_failure(db, credential.id, error_str)
                            last_error = error_str
                            
                            # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•ï¼ˆ404ã€500ã€503 ç­‰é”™è¯¯ï¼‰
                            should_retry = any(code in error_str for code in ["404", "500", "503", "429", "RESOURCE_EXHAUSTED", "NOT_FOUND"])
                            
                            if should_retry and stream_retry < max_retries:
                                print(f"[Proxy] âš ï¸ æµå¼è¯·æ±‚å¤±è´¥: {error_str}ï¼Œåˆ‡æ¢å‡­è¯é‡è¯• ({stream_retry + 2}/{max_retries + 1})", flush=True)
                                
                                # è·å–æ–°å‡­è¯
                                new_credential = await CredentialPool.get_available_credential(
                                    db, user_id=user.id, user_has_public_creds=user_has_public,
                                    model=model, exclude_ids=tried_credential_ids
                                )
                                if new_credential:
                                    tried_credential_ids.add(new_credential.id)
                                    new_token = await CredentialPool.get_access_token(new_credential, db)
                                    if new_token:
                                        credential = new_credential
                                        access_token = new_token
                                        project_id = new_credential.project_id or ""
                                        client = GeminiClient(access_token, project_id)
                                        print(f"[Proxy] ğŸ”„ åˆ‡æ¢åˆ°å‡­è¯: {credential.email}", flush=True)
                                        continue
                            
                            # æ— æ³•é‡è¯•ï¼Œè¾“å‡ºé”™è¯¯
                            await log_usage(500, cred=credential)
                            yield f"data: {json.dumps({'error': f'API Error (å·²é‡è¯• {stream_retry + 1} æ¬¡): {error_str}'})}\n\n"
                            return
                
                return StreamingResponse(
                    stream_generator_with_retry(),
                    media_type="text/event-stream",
                    headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
                )
            else:
                # éæµå¼æ¨¡å¼
                result = await client.chat_completions(
                    model=model,
                    messages=messages,
                    **{k: v for k, v in body.items() if k not in ["model", "messages", "stream"]}
                )
                await log_usage()
                return JSONResponse(content=result)
        
        except Exception as e:
            error_str = str(e)
            await CredentialPool.handle_credential_failure(db, credential.id, error_str)
            last_error = error_str
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
            should_retry = any(code in error_str for code in ["404", "500", "503", "429", "RESOURCE_EXHAUSTED", "NOT_FOUND"])
            
            if should_retry and retry_attempt < max_retries:
                print(f"[Proxy] âš ï¸ è¯·æ±‚å¤±è´¥: {error_str}ï¼Œåˆ‡æ¢å‡­è¯é‡è¯• ({retry_attempt + 2}/{max_retries + 1})", flush=True)
                continue
            
            await log_usage(500)
            raise HTTPException(status_code=500, detail=f"APIè°ƒç”¨å¤±è´¥ (å·²é‡è¯• {retry_attempt + 1} æ¬¡): {error_str}")
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise HTTPException(status_code=503, detail=f"æ‰€æœ‰å‡­è¯éƒ½å¤±è´¥äº†: {last_error}")


# ===== Gemini åŸç”Ÿæ¥å£æ”¯æŒ =====

@router.options("/v1beta/models/{model:path}:generateContent")
@router.options("/v1/models/{model:path}:generateContent")
@router.options("/v1beta/models/{model:path}:streamGenerateContent")
@router.options("/v1/models/{model:path}:streamGenerateContent")
async def gemini_options_handler(model: str):
    """Gemini æ¥å£ CORS é¢„æ£€"""
    return JSONResponse(content={}, headers={
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "*",
    })


@router.get("/v1beta/models")
@router.get("/v1/v1beta/models")
async def list_gemini_models(request: Request, user: User = Depends(get_user_from_api_key), db: AsyncSession = Depends(get_db)):
    """Gemini æ ¼å¼æ¨¡å‹åˆ—è¡¨"""
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ 3.0 å‡­è¯
    has_tier3 = await CredentialPool.has_tier3_credentials(user, db)
    
    base_models = ["gemini-2.5-pro", "gemini-2.5-flash"]
    if has_tier3:
        base_models.append("gemini-3-pro-preview")
    
    models = []
    for base in base_models:
        models.append({
            "name": f"models/{base}",
            "version": "001",
            "displayName": base,
            "description": f"Gemini {base} model",
            "inputTokenLimit": 1000000,
            "outputTokenLimit": 65536,
            "supportedGenerationMethods": ["generateContent", "streamGenerateContent"],
        })
    
    return {"models": models}


@router.post("/v1beta/models/{model:path}:generateContent")
@router.post("/v1/models/{model:path}:generateContent")
@router.post("/v1/v1beta/models/{model:path}:generateContent")
async def gemini_generate_content(
    model: str,
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Gemini åŸç”Ÿ generateContent æ¥å£"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    contents = body.get("contents", [])
    if not contents:
        raise HTTPException(status_code=400, detail="contentsä¸èƒ½ä¸ºç©º")
    
    # æ¸…ç†æ¨¡å‹åï¼ˆç§»é™¤ models/ å‰ç¼€ï¼‰
    if model.startswith("models/"):
        model = model[7:]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶ - ç®¡ç†å‘˜è±å…
    if not user.is_admin:
        one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
        rpm_result = await db.execute(
            select(func.count(UsageLog.id))
            .where(UsageLog.user_id == user.id)
            .where(UsageLog.created_at >= one_minute_ago)
        )
        current_rpm = rpm_result.scalar() or 0
        max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
        
        if current_rpm >= max_rpm:
            raise HTTPException(status_code=429, detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿ")
    
    # è·å–å‡­è¯
    credential = await CredentialPool.get_available_credential(
        db, user_id=user.id, user_has_public_creds=user_has_public, model=model
    )
    if not credential:
        raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯")
    
    access_token = await CredentialPool.get_access_token(credential, db)
    if not access_token:
        raise HTTPException(status_code=503, detail="å‡­è¯å·²å¤±æ•ˆ")
    
    project_id = credential.project_id or ""
    print(f"[Gemini API] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model}", flush=True)
    
    # è®°å½•æ—¥å¿—
    async def log_usage(status_code: int = 200):
        latency = (time.time() - start_time) * 1000
        log = UsageLog(user_id=user.id, credential_id=credential.id, model=model, endpoint="/v1beta/generateContent", status_code=status_code, latency_ms=latency)
        db.add(log)
        credential.total_requests = (credential.total_requests or 0) + 1
        credential.last_used_at = datetime.utcnow()
        await db.commit()
    
    # ç›´æ¥è½¬å‘åˆ° Google API
    try:
        import httpx
        url = "https://cloudcode-pa.googleapis.com/v1internal:generateContent"
        
        # æ„å»º payload
        request_body = {"contents": contents}
        if "generationConfig" in body:
            request_body["generationConfig"] = body["generationConfig"]
        if "systemInstruction" in body:
            request_body["systemInstruction"] = body["systemInstruction"]
        if "safetySettings" in body:
            request_body["safetySettings"] = body["safetySettings"]
        if "tools" in body:
            request_body["tools"] = body["tools"]
        
        payload = {"model": model, "project": project_id, "request": request_body}
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                url,
                headers={"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"},
                json=payload
            )
            
            if response.status_code != 200:
                error_text = response.text[:500]
                print(f"[Gemini API] âŒ é”™è¯¯ {response.status_code}: {error_text}", flush=True)
                # 401/403 é”™è¯¯è‡ªåŠ¨ç¦ç”¨å‡­è¯
                if response.status_code in [401, 403]:
                    await CredentialPool.handle_credential_failure(db, credential.id, f"API Error {response.status_code}: {error_text}")
                await log_usage(response.status_code)
                raise HTTPException(status_code=response.status_code, detail=response.text)
            
            await log_usage()
            
            # è½¬æ¢å“åº”æ ¼å¼ï¼šä»å†…éƒ¨æ ¼å¼è½¬ä¸ºæ ‡å‡† Gemini API æ ¼å¼
            result = response.json()
            if "response" in result:
                # å†…éƒ¨ API æ ¼å¼: {"response": {"candidates": [...]}, "modelVersion": "..."}
                # è½¬ä¸ºæ ‡å‡†æ ¼å¼: {"candidates": [...], "modelVersion": "..."}
                standard_result = result.get("response", {})
                if "modelVersion" in result:
                    standard_result["modelVersion"] = result["modelVersion"]
                return JSONResponse(content=standard_result)
            return JSONResponse(content=result)
    
    except HTTPException:
        raise
    except Exception as e:
        await CredentialPool.handle_credential_failure(db, credential.id, str(e))
        await log_usage(500)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/v1beta/models/{model:path}:streamGenerateContent")
@router.post("/v1/models/{model:path}:streamGenerateContent")
@router.post("/v1/v1beta/models/{model:path}:streamGenerateContent")
async def gemini_stream_generate_content(
    model: str,
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """Gemini åŸç”Ÿ streamGenerateContent æ¥å£"""
    start_time = time.time()
    
    try:
        body = await request.json()
    except:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„JSONè¯·æ±‚ä½“")
    
    contents = body.get("contents", [])
    if not contents:
        raise HTTPException(status_code=400, detail="contentsä¸èƒ½ä¸ºç©º")
    
    # æ¸…ç†æ¨¡å‹å
    if model.startswith("models/"):
        model = model[7:]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å‚ä¸å¤§é”…é¥­
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    
    # é€Ÿç‡é™åˆ¶ - ç®¡ç†å‘˜è±å…
    if not user.is_admin:
        one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
        rpm_result = await db.execute(
            select(func.count(UsageLog.id))
            .where(UsageLog.user_id == user.id)
            .where(UsageLog.created_at >= one_minute_ago)
        )
        current_rpm = rpm_result.scalar() or 0
        max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
        
        if current_rpm >= max_rpm:
            raise HTTPException(status_code=429, detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿ")
    
    # è·å–å‡­è¯
    credential = await CredentialPool.get_available_credential(
        db, user_id=user.id, user_has_public_creds=user_has_public, model=model
    )
    if not credential:
        raise HTTPException(status_code=503, detail="æš‚æ— å¯ç”¨å‡­è¯")
    
    access_token = await CredentialPool.get_access_token(credential, db)
    if not access_token:
        raise HTTPException(status_code=503, detail="å‡­è¯å·²å¤±æ•ˆ")
    
    project_id = credential.project_id or ""
    print(f"[Gemini Stream] ä½¿ç”¨å‡­è¯: {credential.email}, project_id: {project_id}, model: {model}", flush=True)
    
    # è®°å½•æ—¥å¿—
    async def log_usage(status_code: int = 200):
        latency = (time.time() - start_time) * 1000
        log = UsageLog(user_id=user.id, credential_id=credential.id, model=model, endpoint="/v1beta/streamGenerateContent", status_code=status_code, latency_ms=latency)
        db.add(log)
        credential.total_requests = (credential.total_requests or 0) + 1
        credential.last_used_at = datetime.utcnow()
        await db.commit()
    
    # æµå¼è½¬å‘
    import httpx
    url = "https://cloudcode-pa.googleapis.com/v1internal:streamGenerateContent?alt=sse"
    
    request_body = {"contents": contents}
    if "generationConfig" in body:
        request_body["generationConfig"] = body["generationConfig"]
    if "systemInstruction" in body:
        request_body["systemInstruction"] = body["systemInstruction"]
    if "safetySettings" in body:
        request_body["safetySettings"] = body["safetySettings"]
    if "tools" in body:
        request_body["tools"] = body["tools"]
    
    payload = {"model": model, "project": project_id, "request": request_body}
    
    async def stream_generator():
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                async with client.stream(
                    "POST", url,
                    headers={"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"},
                    json=payload
                ) as response:
                    if response.status_code != 200:
                        error = await response.aread()
                        error_text = error.decode()[:500]
                        print(f"[Gemini Stream] âŒ é”™è¯¯ {response.status_code}: {error_text}", flush=True)
                        # 401/403 é”™è¯¯è‡ªåŠ¨ç¦ç”¨å‡­è¯
                        if response.status_code in [401, 403]:
                            await CredentialPool.handle_credential_failure(db, credential.id, f"API Error {response.status_code}: {error_text}")
                        yield f"data: {json.dumps({'error': error.decode()})}\n\n"
                        return
                    
                    async for line in response.aiter_lines():
                        if line:
                            # è½¬æ¢ SSE æ•°æ®æ ¼å¼
                            if line.startswith("data: "):
                                try:
                                    data = json.loads(line[6:])
                                    if "response" in data:
                                        # è½¬æ¢æ ¼å¼
                                        standard_data = data.get("response", {})
                                        if "modelVersion" in data:
                                            standard_data["modelVersion"] = data["modelVersion"]
                                        yield f"data: {json.dumps(standard_data)}\n\n"
                                    else:
                                        yield f"{line}\n"
                                except:
                                    yield f"{line}\n"
                            else:
                                yield f"{line}\n"
            
            await log_usage()
        except Exception as e:
            await CredentialPool.handle_credential_failure(db, credential.id, str(e))
            await log_usage(500)
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return StreamingResponse(
        stream_generator(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )


# ===== OpenAI åŸç”Ÿåä»£ =====

@router.api_route("/openai/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH"])
async def openai_proxy(
    path: str,
    request: Request,
    user: User = Depends(get_user_from_api_key),
    db: AsyncSession = Depends(get_db)
):
    """OpenAI åŸç”Ÿ API åä»£ - ç›´æ¥è½¬å‘åˆ° OpenAI"""
    import httpx
    
    if not settings.openai_api_key:
        raise HTTPException(status_code=503, detail="æœªé…ç½® OpenAI API Keyï¼Œæ— æ³•ä½¿ç”¨ OpenAI åä»£")
    
    start_time = time.time()
    
    # æ£€æŸ¥é€Ÿç‡é™åˆ¶ - ç®¡ç†å‘˜è±å…
    user_has_public = await CredentialPool.check_user_has_public_creds(db, user.id)
    if not user.is_admin:
        one_minute_ago = datetime.utcnow() - timedelta(minutes=1)
        rpm_result = await db.execute(
            select(func.count(UsageLog.id))
            .where(UsageLog.user_id == user.id)
            .where(UsageLog.created_at >= one_minute_ago)
        )
        current_rpm = rpm_result.scalar() or 0
        max_rpm = settings.contributor_rpm if user_has_public else settings.base_rpm
        
        if current_rpm >= max_rpm:
            raise HTTPException(status_code=429, detail=f"é€Ÿç‡é™åˆ¶: {max_rpm} æ¬¡/åˆ†é’Ÿ")
    
    # æ„å»ºç›®æ ‡ URL
    target_url = f"{settings.openai_api_base}/{path}"
    if request.query_params:
        target_url += f"?{request.query_params}"
    
    # è·å–è¯·æ±‚ä½“
    body = None
    if request.method in ["POST", "PUT", "PATCH"]:
        body = await request.body()
    
    # æ„å»ºè¯·æ±‚å¤´ï¼ˆæ›¿æ¢ Authorizationï¼‰
    headers = dict(request.headers)
    headers["Authorization"] = f"Bearer {settings.openai_api_key}"
    # ç§»é™¤ host å¤´
    headers.pop("host", None)
    headers.pop("Host", None)
    
    # è®°å½•æ—¥å¿—
    async def log_usage(status_code: int = 200):
        latency = (time.time() - start_time) * 1000
        log = UsageLog(
            user_id=user.id,
            credential_id=None,
            model="openai",
            endpoint=f"/openai/{path}",
            status_code=status_code,
            latency_ms=latency
        )
        db.add(log)
        await db.commit()
        await notify_log_update({
            "username": user.username,
            "model": "openai",
            "status_code": status_code,
            "latency_ms": round(latency, 0),
            "created_at": datetime.utcnow().isoformat()
        })
        await notify_stats_update()
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯æµå¼è¯·æ±‚
    is_stream = False
    if body:
        try:
            body_json = json.loads(body)
            is_stream = body_json.get("stream", False)
        except:
            pass
    
    print(f"[OpenAI Proxy] {request.method} {target_url}, stream={is_stream}", flush=True)
    
    try:
        if is_stream:
            # æµå¼å“åº”
            async def stream_generator():
                try:
                    async with httpx.AsyncClient(timeout=120.0) as client:
                        async with client.stream(
                            request.method, target_url,
                            headers=headers,
                            content=body
                        ) as response:
                            if response.status_code != 200:
                                error = await response.aread()
                                await log_usage(response.status_code)
                                yield f"data: {json.dumps({'error': error.decode()})}\n\n"
                                return
                            
                            async for line in response.aiter_lines():
                                if line:
                                    yield f"{line}\n"
                    
                    await log_usage()
                except Exception as e:
                    await log_usage(500)
                    yield f"data: {json.dumps({'error': str(e)})}\n\n"
            
            return StreamingResponse(
                stream_generator(),
                media_type="text/event-stream",
                headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
            )
        else:
            # éæµå¼å“åº”
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.request(
                    request.method, target_url,
                    headers=headers,
                    content=body
                )
                
                await log_usage(response.status_code)
                
                # è¿”å›å“åº”
                return JSONResponse(
                    content=response.json() if response.headers.get("content-type", "").startswith("application/json") else {"text": response.text},
                    status_code=response.status_code
                )
    
    except Exception as e:
        await log_usage(500)
        raise HTTPException(status_code=500, detail=f"OpenAI API è¯·æ±‚å¤±è´¥: {str(e)}")
